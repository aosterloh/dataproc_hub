{"cells": [{"cell_type": "markdown", "metadata": {"id": "J3TwAK_8Wll0"}, "source": "## 3. Data Scientist - Create ML models with Spark\n\n### This notebook creates ML models using Spark"}, {"cell_type": "code", "execution_count": 1, "metadata": {"id": "rwCbd6SqWll0"}, "outputs": [], "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator\nimport re"}, {"cell_type": "code", "execution_count": 2, "metadata": {"id": "g7hujos_zCwi"}, "outputs": [], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n.appName('Spark - Data Scientist Demo') \\\n.config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest.jar') \\\n.config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.18.0\") \\\n.getOrCreate()"}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "mZAK-gbxzCwj"}, "outputs": [{"data": {"text/plain": "'version 2.12.10'"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "spark.conf.get(\"spark.app.id\")\nspark.sparkContext._jvm.scala.util.Properties.versionString()"}, {"cell_type": "code", "execution_count": 4, "metadata": {"id": "ylnHDJ13zCwj"}, "outputs": [{"data": {"text/plain": "'thatistoomuchdata:thatistoomuchdata_raw.transaction_data_train'"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "project_id = !gcloud config list --format 'value(core.project)' 2>/dev/null\nbq_raw_dataset_name = project_id[0] + '-raw'\nbq_raw_dataset_name = bq_raw_dataset_name.replace('-', '_')\nbq_raw_table_path = project_id[0] + ':' + bq_raw_dataset_name + '.transaction_data_train' \nbq_raw_table_path"}, {"cell_type": "markdown", "metadata": {"id": "asGBbiH5zCwk"}, "source": "#### Load Training Data using Spark"}, {"cell_type": "code", "execution_count": 5, "metadata": {"id": "p20yxBKHzCwl"}, "outputs": [], "source": "data = spark.read \\\n.format(\"bigquery\") \\\n.option(\"table\", bq_raw_table_path) \\\n.load()"}, {"cell_type": "code", "execution_count": 6, "metadata": {"id": "_y4K036kzCwn"}, "outputs": [{"data": {"text/plain": "DataFrame[step: bigint, type: string, amount: double, oldbalanceOrg: double, newbalanceOrig: double, oldbalanceDest: double, newbalanceDest: double, isFraud: bigint]"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "data = data.drop('transactionID')\ndata.cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Oversampling the minority label (isFraud=1)"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "ratio: 780\n"}], "source": "from pyspark.sql.functions import col, explode, array, lit\n\nmajor_df = data.filter(col(\"isFraud\") == 0)\nminor_df = data.filter(col(\"isFraud\") == 1)\nratio = int(major_df.count()/minor_df.count())\nprint(\"ratio: {}\".format(ratio))"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+--------+----------+-------------+--------------+--------------+--------------+-------+\n|step|    type|    amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|\n+----+--------+----------+-------------+--------------+--------------+--------------+-------+\n| 394|TRANSFER| 907383.75|     299092.0|           0.0|     376940.81|    1284324.57|      0|\n| 157|TRANSFER| 717295.33|    261603.06|           0.0|     807600.99|    1524896.32|      0|\n| 377|TRANSFER|  61051.45|         79.0|           0.0|      80740.22|     141791.67|      0|\n| 277|TRANSFER| 916955.98|      16659.0|           0.0|    6834829.74|    7751785.72|      0|\n| 573|TRANSFER| 143256.09|      29448.0|           0.0|     261053.61|     404309.71|      0|\n| 500|TRANSFER|  22501.12|      50363.0|      27861.88|     104619.77|     127120.88|      0|\n| 179|TRANSFER| 283076.02|     118174.0|           0.0|    1565602.22|    1848678.24|      0|\n| 373|TRANSFER|1367488.13|      21237.0|           0.0|      36733.42|    1404221.55|      0|\n| 324|TRANSFER|1020792.71|      31604.0|           0.0|      52806.06|    1073598.77|      0|\n| 129|TRANSFER|2098502.92|      41169.0|           0.0|      60895.46|    2159398.38|      0|\n| 353|TRANSFER| 207048.49|       7395.0|           0.0| 1.136261436E7| 1.156966285E7|      0|\n| 373|TRANSFER| 701352.13|    152419.42|           0.0|    2613608.51|    3314960.65|      0|\n| 357|TRANSFER|  76234.22|        174.0|           0.0|     707528.23|     783762.46|      0|\n| 239|TRANSFER| 153672.92|      10841.0|           0.0|      48458.97|     202131.89|      0|\n| 249|TRANSFER|  484954.0|     30985.79|           0.0|    1630432.09|    2115386.09|      0|\n| 282|TRANSFER| 205610.91|    186904.97|           0.0|     350964.85|     556575.76|      0|\n| 179|TRANSFER| 962572.93|    232104.54|           0.0|     1791819.7|    2754392.63|      0|\n| 327|TRANSFER| 3374806.4|      80718.0|           0.0|     646396.46|    4021202.87|      0|\n| 405|TRANSFER| 147651.72|      30988.0|           0.0|     613231.34|     760883.06|      0|\n| 406|TRANSFER| 244084.99|     584799.0|     340714.01| 1.138937612E7| 1.163346111E7|      0|\n+----+--------+----------+-------------+--------------+--------------+--------------+-------+\nonly showing top 20 rows\n\n"}], "source": "# duplicate the minority rows\noversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in range(ratio)]))).drop('dummy')\n# combine both oversampled minority rows and previous majority rows\ndata = major_df.unionAll(oversampled_df)\ndata.show()"}, {"cell_type": "markdown", "metadata": {"id": "oGTkXZhtzCwn"}, "source": "#### Create a pyspark ML pipeline \n\nThe pipeline will transform the features and train a Decision Tree classifier "}, {"cell_type": "code", "execution_count": 9, "metadata": {"id": "2kg4ewsvzCwo"}, "outputs": [], "source": "from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier\n\n\ncategorical_cols = [field for (field, data_type) in data.dtypes \n                    if ((data_type == \"string\") & (field != 'isFraud'))]\n\nohe_output_cols = [x + \"_OHE\" for x in categorical_cols]\n\nstring_indexers = StringIndexer(inputCol='type', outputCol='type' +\"_Index\").fit(data) \n\none_hot_indexer = OneHotEncoder(inputCol='type_Index', outputCol='type' +\"_OHE\")\n\nnumeric_cols = [field for (field, data_type) in data.dtypes \n                if (((data_type == \"double\") | (data_type == \"int\") | (data_type == \"bigint\"))\n                  & (field != 'isFraud'))]\n\nassembler_inputs = ohe_output_cols + numeric_cols\n\nvec_assembler = VectorAssembler(\n    inputCols=assembler_inputs,\n    outputCol=\"features\")\n\n#DecisionTree\ndtc = DecisionTreeClassifier(labelCol=\"isFraud\", featuresCol=\"features\", maxDepth=3, maxBins=12)\n# #Linear Regression\n# dtc = LogisticRegression(labelCol=\"isFraud\", featuresCol=\"features\", maxIter=10, )\n\npipeline = Pipeline(stages=[\n    string_indexers,\n    one_hot_indexer,\n    vec_assembler,\n    dtc \n])"}, {"cell_type": "markdown", "metadata": {}, "source": "## Hyperparameter tuning"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\nparamGrid = ParamGridBuilder() \\\n    .addGrid(dtc.maxDepth, [3, 6, 10, 11 ]) \\\n    .addGrid(dtc.maxBins, [12, 24, 200]) \\\n    .build()\n# #Linear Regression\n# paramGrid = ParamGridBuilder() \\\n#     .addGrid(lr.regParam, [0.1, 0.01]) \\\n#     .build()\n\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=BinaryClassificationEvaluator(labelCol=\"isFraud\"),\n                          numFolds=2)\n\n# Run cross-validation, and choose the best set of parameters.\nmodel = crossval.fit(data)"}, {"cell_type": "markdown", "metadata": {"id": "--lPFc7mzCwp"}, "source": "#### Train the model "}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "kGU9h1-rzCwq"}, "outputs": [], "source": "model = pipeline.fit(data)"}, {"cell_type": "markdown", "metadata": {"id": "vqH9COddzCwq"}, "source": "#### Persist the model to GCS "}, {"cell_type": "code", "execution_count": 12, "metadata": {"id": "cnoutgo2zCwq"}, "outputs": [], "source": "from pyspark.ml import Pipeline, PipelineModel\n\ngcs_bucket = project_id[0] + '-data'\nmodel_path = f'gs://{gcs_bucket}/model/'\n# model = model.bestModel\nmodel.write().overwrite().save(model_path)"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Predict on test data\n**TODO** \n\n* Provide path_to_predict_csv"}, {"cell_type": "code", "execution_count": 13, "metadata": {"id": "DdasXGm7zCws"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- step: integer (nullable = true)\n |-- type: string (nullable = true)\n |-- amount: double (nullable = true)\n |-- oldbalanceOrg: double (nullable = true)\n |-- newbalanceOrig: double (nullable = true)\n |-- oldbalanceDest: double (nullable = true)\n |-- newbalanceDest: double (nullable = true)\n |-- isFraud: integer (nullable = true)\n |-- transactionID: string (nullable = true)\n\n"}], "source": "path_to_predict_csv = \"gs://thetraining-project-data/transaction_data_test.csv\"\ndf_transaction_data_predict_from_csv = spark \\\n.read \\\n.option(\"inferSchema\" , \"true\") \\\n.option(\"header\" , \"true\") \\\n.csv(path_to_predict_csv)\ndf_transaction_data_predict_from_csv.printSchema()"}, {"cell_type": "markdown", "metadata": {"id": "LRp9QM2jzCws"}, "source": "Load the saved model "}, {"cell_type": "code", "execution_count": 14, "metadata": {"id": "YFjQsf5pzCws"}, "outputs": [], "source": "loaded_pipeline_model = PipelineModel.load(model_path)"}, {"cell_type": "code", "execution_count": 15, "metadata": {"id": "Wd2X6ZbBzCwt"}, "outputs": [], "source": "predictions = loaded_pipeline_model.transform(df_transaction_data_predict_from_csv)"}, {"cell_type": "code", "execution_count": 16, "metadata": {"id": "BaR6_kfazCwt"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----+-----+-------+-------------+--------------+--------------+--------------+-------+--------------------+----------+---------+--------------------+--------------------+--------------------+----------+\n|step| type| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|       transactionID|type_Index| type_OHE|            features|       rawPrediction|         probability|prediction|\n+----+-----+-------+-------------+--------------+--------------+--------------+-------+--------------------+----------+---------+--------------------+--------------------+--------------------+----------+\n| 310|DEBIT|3334.31|     102439.0|      99104.69|     962290.61|     965624.92|      0|818ca43a-9ac9-484...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|\n| 351|DEBIT|5268.56|        468.0|           0.0|    1672373.71|    1677642.27|      0|70948920-5fa6-401...|       4.0|(4,[],[])|(10,[4,5,6,8,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|\n| 592|DEBIT| 3016.8|      62038.0|       59021.2|    9669792.89|    9672809.69|      0|c6bbbaf0-55bb-4e9...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|\n| 286|DEBIT|2005.45|     462875.0|     460869.55|     757666.15|      759671.6|      0|a8b178e2-6e70-42f...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|\n| 157|DEBIT|7422.22|      20639.0|      13216.78|    3957547.41|    3964969.63|      0|9931bfd1-0b59-4d3...|       4.0|(4,[],[])|[0.0,0.0,0.0,0.0,...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|\n+----+-----+-------+-------------+--------------+--------------+--------------+-------+--------------------+----------+---------+--------------------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n"}], "source": "predictions.show(5)"}, {"cell_type": "code", "execution_count": 17, "metadata": {"id": "2FFk6q7fzCwt"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-------+\n|prediction|isFraud|\n+----------+-------+\n|       0.0|      0|\n|       0.0|      0|\n|       0.0|      0|\n|       0.0|      0|\n|       0.0|      0|\n+----------+-------+\nonly showing top 5 rows\n\n"}], "source": "# Select example rows to display.\npredictions.select(\"prediction\", \"isFraud\").show(5)"}, {"cell_type": "markdown", "metadata": {"id": "TBMiTQJqzCwu"}, "source": "### Evaluate the model"}, {"cell_type": "code", "execution_count": 18, "metadata": {"id": "_KYod7wWzCwu"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0.8908125351606421\n"}], "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nbinaryEvaluator = BinaryClassificationEvaluator(labelCol=\"isFraud\")\n\nauc = binaryEvaluator.evaluate(predictions, {binaryEvaluator.metricName: \"areaUnderROC\"})\nprint(auc)"}, {"cell_type": "code", "execution_count": 19, "metadata": {"id": "FXJV0AQgzCwu"}, "outputs": [{"data": {"text/plain": "array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]])"}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "tests_np = np.array((predictions.select(\"isFraud\",\"prediction\").collect()))\ntests_np"}, {"cell_type": "code", "execution_count": 20, "metadata": {"id": "SCbijvh6zCwv"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "f1: 0.03849006322828806\nprecision: 0.0196647614154518\nrecall: 0.9016489988221437\n"}], "source": "tests_np = np.array((predictions.select(\"isFraud\",\"prediction\").collect()))\n\nnp_acc = accuracy_score(tests_np[:,0], tests_np[:,1])\nnp_f1 = f1_score(tests_np[:,0], tests_np[:,1])\nnp_precision = precision_score(tests_np[:,0], tests_np[:,1])\nnp_recall = recall_score(tests_np[:,0], tests_np[:,1])\nnp_auc = roc_auc_score(tests_np[:,0], tests_np[:,1])\n\nprint(\"f1:\", np_f1)\nprint(\"precision:\", np_precision)\nprint(\"recall:\", np_recall)"}, {"cell_type": "markdown", "metadata": {"id": "PlDr0C5DzCwv"}, "source": "#### Create confusion matrix"}, {"cell_type": "code", "execution_count": 21, "metadata": {"id": "D0-_eqAszCwv"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted Positive(1)</th>\n      <th>Predicted Negative(0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Actual Positive(1)</th>\n      <td>1531</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>Actual Negative(0)</th>\n      <td>76324</td>\n      <td>1193906</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                    Predicted Positive(1)  Predicted Negative(0)\nActual Positive(1)                   1531                    167\nActual Negative(0)                  76324                1193906"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "# import package that will generate the confusion matrix scores\nfrom sklearn.metrics import confusion_matrix\n# import packages that will help display the scores\nimport pandas as pd\n\nconfusion_matrix_scores = confusion_matrix(tests_np[:,0], \n                                           tests_np[:,1], \n                                           labels=[1, 0])\n\n# display scores as a heatmap\ndf = pd.DataFrame(confusion_matrix_scores, \n                  columns = [\"Predicted Positive(1)\", \"Predicted Negative(0)\"],\n                  index = [\"Actual Positive(1)\", \"Actual Negative(0)\"])\n\n\ndf.head()"}, {"cell_type": "code", "execution_count": 22, "metadata": {"id": "8Q3YHVvezCww"}, "outputs": [{"data": {"text/plain": "'thetraining_project_annotated.transaction_data_predictions'"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "bq_annotated_table_name = 'transaction_data_predictions'\nbq_annotated_table_path=  project_id[0] +  '_annotated.' + bq_annotated_table_name\nbq_annotated_table_path = bq_annotated_table_path.replace('-', '_')\nbq_annotated_table_path"}, {"cell_type": "markdown", "metadata": {"id": "cDn4bdq1zCww"}, "source": "#### Persist predictions as an annotated dataset"}, {"cell_type": "code", "execution_count": 37, "metadata": {"id": "vwfUAozUzCwx"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "BigQuery error in mk operation: Table 'thetraining-\nproject:thetraining_project_annotated.transaction_data_predictions' could not be\ncreated; a table with this name already exists.\n"}], "source": "schema_inline = predictions.schema.simpleString().replace('struct<', '').replace('>', '').replace('int', 'int64').replace('double', 'float64').replace('bigint64', 'int64').replace('vector', 'STRING')\n\n!bq mk --table \\\n{bq_annotated_table_path} \\\n{schema_inline}"}, {"cell_type": "code", "execution_count": 38, "metadata": {}, "outputs": [{"data": {"text/plain": "'step:int64,type:string,amount:float64,oldbalanceOrg:float64,newbalanceOrig:float64,oldbalanceDest:float64,newbalanceDest:float64,isFraud:int64,transactionID:string,type_Index:float64,type_OHE:STRING,features:STRING,rawPrediction:STRING,probability:STRING,prediction:float64'"}, "execution_count": 38, "metadata": {}, "output_type": "execute_result"}], "source": "schema_inline"}, {"cell_type": "code", "execution_count": 24, "metadata": {"id": "mKDzZWhTzCwx"}, "outputs": [], "source": "predictions.write \\\n.format(\"bigquery\") \\\n.option(\"table\", project_id[0]  + ':' + bq_annotated_table_path) \\\n.option(\"temporaryGcsBucket\", project_id[0]  + '-data') \\\n.mode('overwrite') \\\n.save()"}, {"cell_type": "code", "execution_count": 25, "metadata": {"id": "B6EreECmzCwy"}, "outputs": [{"data": {"text/plain": "'thetraining_project_annotated'"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "annotated_dataset_name =  project_id[0] +  '_annotated'\nannotated_dataset_name = annotated_dataset_name.replace('-', '_')\nannotated_dataset_name"}, {"cell_type": "markdown", "metadata": {"id": "OGwxhnHGzCwy"}, "source": "**TODO** \n* Add annotated_dataset_name in the FROM clause below"}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "2-gJPCtxzCwz"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>table_catalog</th>\n      <th>table_schema</th>\n      <th>table_name</th>\n      <th>table_type</th>\n      <th>is_insertable_into</th>\n      <th>is_typed</th>\n      <th>creation_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thetraining-project</td>\n      <td>thetraining_project_annotated</td>\n      <td>transaction_data_workflow</td>\n      <td>BASE TABLE</td>\n      <td>YES</td>\n      <td>NO</td>\n      <td>2021-03-15 11:41:26.369000+00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>thetraining-project</td>\n      <td>thetraining_project_annotated</td>\n      <td>transaction_data_predictions</td>\n      <td>BASE TABLE</td>\n      <td>YES</td>\n      <td>NO</td>\n      <td>2021-03-03 09:56:08.781000+00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "         table_catalog                   table_schema  \\\n0  thetraining-project  thetraining_project_annotated   \n1  thetraining-project  thetraining_project_annotated   \n\n                     table_name  table_type is_insertable_into is_typed  \\\n0     transaction_data_workflow  BASE TABLE                YES       NO   \n1  transaction_data_predictions  BASE TABLE                YES       NO   \n\n                     creation_time  \n0 2021-03-15 11:41:26.369000+00:00  \n1 2021-03-03 09:56:08.781000+00:00  "}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": "%%bigquery\nSELECT * FROM thetraining_project_annotated.INFORMATION_SCHEMA.TABLES;"}, {"cell_type": "markdown", "metadata": {"id": "wbZpvQ9nzCwz"}, "source": "#### Join buisness data to enrich the dataset"}, {"cell_type": "markdown", "metadata": {"id": "k00qmMINzCwz"}, "source": "**TODO** \n* Provide the path to the join csv"}, {"cell_type": "code", "execution_count": 27, "metadata": {"id": "zf_shWXdzCw0"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- nameOrig: string (nullable = true)\n |-- nameDest: string (nullable = true)\n |-- transactionID: string (nullable = true)\n\n"}], "source": "path_to_join_csv = \"gs://thetraining-project-data/transaction_data_join.csv\"\ndf_transaction_data_join_from_csv = spark \\\n.read \\\n.option(\"inferSchema\" , \"true\") \\\n.option(\"header\" , \"true\") \\\n.csv(path_to_join_csv)\ndf_transaction_data_join_from_csv.printSchema()"}, {"cell_type": "markdown", "metadata": {"id": "mjGflyBOzCw0"}, "source": "**TODO** (Challenge 2)\n* Join the 2 spark dataframes (predictions & df_transaction_data_join_from_csv) on transactionID field "}, {"cell_type": "code", "execution_count": 28, "metadata": {"id": "pm-AH24IzCw1"}, "outputs": [], "source": "joined_result = predictions.join(df_transaction_data_join_from_csv, \"transactionID\")"}, {"cell_type": "code", "execution_count": 29, "metadata": {"id": "vFE7tsZczCw1"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+----+--------+---------+-------------+--------------+--------------+--------------+-------+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-----------+\n|       transactionID|step|    type|   amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|isFraud|type_Index|     type_OHE|            features|       rawPrediction|         probability|prediction|   nameOrig|   nameDest|\n+--------------------+----+--------+---------+-------------+--------------+--------------+--------------+-------+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-----------+\n|0013918d-0cdc-4e2...| 306|   DEBIT|  1244.34|      30927.0|      29682.66|    3248801.84|    3250046.18|      0|       4.0|    (4,[],[])|[0.0,0.0,0.0,0.0,...|[3265139.0,408720.0]|[0.88874913272392...|       0.0| C831886474|C1847064333|\n|00162366-932d-4fc...| 204|CASH_OUT|203860.23|          0.0|           0.0|     336504.92|     540365.16|      0|       0.0|(4,[0],[1.0])|(10,[0,4,5,8,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0| C896728022| C331131087|\n|0022ef6a-0ee3-4e8...|  13|CASH_OUT| 382105.5|          0.0|           0.0|    2750925.15|    3133030.66|      0|       0.0|(4,[0],[1.0])|(10,[0,4,5,8,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|C1150532907|C1660526430|\n|003402a4-bc23-4f2...| 178| PAYMENT| 27994.13|      69545.0|      41550.87|           0.0|           0.0|      0|       2.0|(4,[2],[1.0])|(10,[2,4,5,6,7],[...|  [1420940.0,2340.0]|[0.99835591029172...|       0.0|C1260774996| M740485457|\n|0036a79e-5f07-4ec...| 209|CASH_OUT|329965.55|        456.0|           0.0|           0.0|     329965.55|      0|       0.0|(4,[0],[1.0])|(10,[0,4,5,6,9],[...|[3265139.0,408720.0]|[0.88874913272392...|       0.0|C1471278494| C408482446|\n+--------------------+----+--------+---------+-------------+--------------+--------------+--------------+-------+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-----------+\nonly showing top 5 rows\n\n"}], "source": "joined_result.show(5)"}, {"cell_type": "code", "execution_count": 30, "metadata": {"id": "a2uQsRCbzCw2"}, "outputs": [{"data": {"text/plain": "1271928"}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": "joined_result.count()"}, {"cell_type": "markdown", "metadata": {"id": "9K33zizTzCw2"}, "source": "#### Persist result as an enriched dataset"}, {"cell_type": "code", "execution_count": 31, "metadata": {"id": "QsiOiwSOzCw2"}, "outputs": [{"data": {"text/plain": "'thetraining-project:thetraining_project_enriched.transaction_analysis_enriched'"}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": "bq_enriched_table_name = 'transaction_analysis_enriched'\nbq_enriched_table_path = project_id[0] +  '_enriched.' + bq_enriched_table_name\nbq_enriched_table_path = bq_enriched_table_path.replace('-', '_')\nbq_enriched_table_path = project_id[0] + ':' + bq_enriched_table_path\nbq_enriched_table_path"}, {"cell_type": "code", "execution_count": 32, "metadata": {"id": "6zl_7sFOzCw2"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "BigQuery error in mk operation: Table 'thetraining-\nproject:thetraining_project_enriched.transaction_analysis_enriched' could not be\ncreated; a table with this name already exists.\n"}], "source": "schema_inline = joined_result.schema.simpleString().replace('struct<', '').replace('>', '').replace('int', 'int64').replace('bigint64', 'int64').replace('double', 'float64').replace('vector', 'STRING')\n\n!bq mk --table \\\n{bq_enriched_table_path} \\\n{schema_inline}"}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [{"data": {"text/plain": "'transactionID:string,step:int64,type:string,amount:float64,oldbalanceOrg:float64,newbalanceOrig:float64,oldbalanceDest:float64,newbalanceDest:float64,isFraud:int64,type_Index:float64,type_OHE:STRING,features:STRING,rawPrediction:STRING,probability:STRING,prediction:float64,nameOrig:string,nameDest:string'"}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": "schema_inline"}, {"cell_type": "code", "execution_count": 34, "metadata": {"id": "xG1fvtj6zCw3"}, "outputs": [], "source": "joined_result.write \\\n.format(\"bigquery\") \\\n.option(\"table\", bq_enriched_table_path) \\\n.option(\"temporaryGcsBucket\", project_id[0]  + '-data') \\\n.mode('overwrite') \\\n.save()"}, {"cell_type": "code", "execution_count": 35, "metadata": {"id": "dN-MyDCszCw3"}, "outputs": [{"data": {"text/plain": "'thetraining_project_enriched'"}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": "enriched_dataset_name = project_id[0] +  '_enriched'\nenriched_dataset_name = enriched_dataset_name.replace('-', '_')\nenriched_dataset_name"}, {"cell_type": "markdown", "metadata": {"id": "qtXtLcrXzCw3"}, "source": "**TODO**\n* Provide the enriched_dataset_name in the FROM clause"}, {"cell_type": "code", "execution_count": 36, "metadata": {"id": "nbiRVokHzCw4"}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>table_catalog</th>\n      <th>table_schema</th>\n      <th>table_name</th>\n      <th>table_type</th>\n      <th>is_insertable_into</th>\n      <th>is_typed</th>\n      <th>creation_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thetraining-project</td>\n      <td>thetraining_project_enriched</td>\n      <td>transaction_analysis_enriched</td>\n      <td>BASE TABLE</td>\n      <td>YES</td>\n      <td>NO</td>\n      <td>2021-03-03 12:09:03.854000+00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "         table_catalog                  table_schema  \\\n0  thetraining-project  thetraining_project_enriched   \n\n                      table_name  table_type is_insertable_into is_typed  \\\n0  transaction_analysis_enriched  BASE TABLE                YES       NO   \n\n                     creation_time  \n0 2021-03-03 12:09:03.854000+00:00  "}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": "%%bigquery\nSELECT * FROM thetraining_project_enriched.INFORMATION_SCHEMA.TABLES;"}, {"cell_type": "markdown", "metadata": {}, "source": "**TODO**\n* Query the enriched table"}, {"cell_type": "markdown", "metadata": {"id": "UY96LzmUzCw4"}, "source": "**TODO** (Optional: Challenge 3)\n* Improve the ML pipeline\n    * Try out different ML models [[doc]](https://spark.apache.org/docs/latest/ml-pipeline.html)\n    * Explore hyperparameter tuning \n    * How would you split the data when there is class imbalance? "}], "metadata": {"colab": {"name": "3_Data_Scientist.ipynb", "provenance": []}, "kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}